{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file has the generator and discriminator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.full.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(g_image, reuse=None):\n",
    "    with tf.variable_scope('g', reuse=reuse):\n",
    "        \n",
    "        # g_image will have the random noise with (1x1x100) dimensions\n",
    "        gnet = helper_conv2d_transpose(g_image, 512, (1,1), 'valid')\n",
    "        gnet = tf.layers.batch_normalization(inputs = gnet)\n",
    "        gnet = tf.nn.relu(gnet)\n",
    "\n",
    "        gnet = helper_conv2d_transpose(gnet, 256)\n",
    "        gnet = tf.layers.batch_normalization(inputs = gnet)\n",
    "        gnet = tf.nn.relu(gnet)\n",
    "                \n",
    "        gnet = helper_conv2d_transpose(gnet, 128, (1,1))\n",
    "        gnet = tf.layers.batch_normalization(inputs = gnet)\n",
    "        gnet = tf.nn.relu(gnet)\n",
    "              \n",
    "        gnet = helper_conv2d_transpose(gnet, 64)\n",
    "        gnet = tf.layers.batch_normalization(inputs = gnet)\n",
    "        gnet = tf.nn.relu(gnet)\n",
    "                      \n",
    "        gnet = helper_conv2d_transpose(gnet, 3)\n",
    "        \n",
    "        gnet = tf.nn.tanh(gnet)\n",
    "        \n",
    "        return gnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=None):\n",
    "    with tf.variable_scope('d', reuse=reuse):\n",
    "        \n",
    "        # x_image will take true images and generator images alternatively\n",
    "        # same weights will be used(reuse=True) to train both fake and real images\n",
    "        dnet = helper_conv2d(x_image, 64)\n",
    "        dnet = tf.nn.leaky_relu(dnet)                        \n",
    "    \n",
    "        dnet = helper_conv2d(dnet, 128)\n",
    "        dnet = tf.layers.batch_normalization(inputs = dnet)\n",
    "        dnet = tf.nn.leaky_relu(dnet)\n",
    "\n",
    "        dnet = helper_conv2d(dnet, 256)\n",
    "        dnet = tf.layers.batch_normalization(inputs = dnet)\n",
    "        dnet = tf.nn.leaky_relu(dnet)\n",
    "             \n",
    "        dnet = helper_conv2d(dnet, 512)\n",
    "        dnet = tf.layers.batch_normalization(inputs = dnet)\n",
    "        dnet = tf.nn.leaky_relu(dnet)    \n",
    "        \n",
    "        #dnet = helper_conv2d(dnet, 1, (1,1), 'valid')\n",
    "        \n",
    "        dnet = tf.layers.flatten(dnet)\n",
    "        \n",
    "        dnet = tf.layers.dense(dnet, 1024, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        dnet = tf.layers.dropout(dnet, 0.5)\n",
    "        \n",
    "        dnet = tf.layers.dense(dnet, 128, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        dnet = tf.layers.dropout(dnet, 0.5)\n",
    "        \n",
    "        dnet = tf.layers.dense(dnet, 1, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        out = tf.nn.sigmoid(dnet)\n",
    "           \n",
    "        return out, dnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'd/Sigmoid:0' shape=(50, 1) dtype=float32>,\n",
       " <tf.Tensor 'd/dense_2/BiasAdd:0' shape=(50, 1) dtype=float32>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#discriminator(tf.placeholder(tf.float32, [50, 32,32,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'g/Tanh:0' shape=(50, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generator(tf.placeholder(tf.float32, [50, 1,1,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1, 1, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.random.uniform(-1.0, 1.0, [50, 1,1,100]).astype(np.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
